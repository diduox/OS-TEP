#### 空闲空间管理

如果要管理的空闲空间由大小不同的单元构成，管理就变的困难（而且有趣(什么抖m)）。这种清空出现在用户级的内存分配库（如malloc()和free()），或者操作系统用分段（segmentation）的方式实现虚拟内存。在这两种情况下，出现了外部碎片（external fragmentation）的问题：空闲空间被分割成不同大小的小块，成为碎片，后去的请求可能失败，因为没有一块足够大的来连续空闲空间，即使这是总的空闲空间超出了请求的大小。

例如：

![](D:\OS-TEP\OS-TEP\note\第17章 空闲空间管理\屏幕截图 2024-01-31 231156.png)

上面展示了该问题的一个例子。在这个例子中，全部可用空闲空间是20字节，但被切成 两个10字节大小的碎片，导致一个15字节的分配请求失败。

> **关键问题：如何管理空闲空间**  
>
> 要满足变长的分配请求，应该如何管理空闲空间？什么策略可以让碎片最小化？不同方法的时间和 空间开销如何？

##### 17.1   假设

**我们假定**基本的接口就像malloc()和free()提供的那样。

具体来说，void* malloc(size t size)需要一个参数size，它是应用程序请求的字节数。函数返回一个指针（没有具体的类型，C语言中是void），指向这样大小（或较大一点）的一块空间。

对应的函数void free(void *ptr)函数接受这一个指针，释放对应的内存块。

请注意该接口的隐含意义，在释放空间时，用户不需告知库这块空间的大小。因此，在只传入一个指针的情况下，库必须能够弄清这块内存的大小。

该库管理的空间由于历史原因被称为堆，在堆上管理空闲空间的数据结构通常称为空闲列表（free list）。该结构包含了管理内存区域中所有空闲块的引用。当然，该数据结构不一定真的是列表，而是某种可以追踪空闲空间的数据结构。

**进一步假设**，我们主要关心的是外部碎片（external fragmentation），如上所述。当然， 分配程序也可能有内部碎片（internal fragmentation）的问题。

- 内部碎片：分配程序给出的内存块超出请求的大小，位于已经被分配的内存内部的碎片，这是另一种形式的空间浪费。
- 外部碎片：未被分配的内存，但因为某些原因太小而导致无法被分配出去。

**我们还假设**，内存一旦被分配给客户，就不可以被重定位到其他位置。

例如，一个程序调用malloc()，并获得一个指向堆中一块空间的指针，这块区域就“属于”这个程序了， 库不再能够移动，直到程序调用相应的 free()函数将它归还。

因此，不可能进行紧凑 （compaction）空闲空间的操作，从而减少碎片。（此操作存在于更强类型的、带垃圾收集的语言中，C语言不能使用）。

但是，操作系统层在实现分段（segmentation） 时，却可以通过紧凑来减少碎片。

**最后我们假设**，分配程序所管理的是连续的一块字节区域。在一些情况下，分配程序可以要求这块区域增长。但是，简单起见，我们假设这块区域在整个生 命周期内大小固定。

##### 17.2   底层机制 

再深入策略细节之前，我们先来介绍大多数分配程序采用的通用机制。

首先，探讨空间分割和合并的基本知识。其次，看看如何快速并相对轻松的追踪以分配的空间。最后，讨论如何利用空闲区域的内部空间维护一个简单的列表，来追踪空闲和已分配的空间。

###### 分割与合并 

空闲列表包含一组元素，记录了堆中的哪些空间还没有分配。假设有下面的30字节的堆：

![](D:\OS-TEP\OS-TEP\note\第17章 空闲空间管理\屏幕截图 2024-01-31 234248.png)

这个堆对应的空闲列表会有两个元素，一个描述第一个10字节的空闲区域（字节0～9）， 一个描述另一个空闲区域（字节20～29）

<img src="D:\OS-TEP\OS-TEP\note\第17章 空闲空间管理\屏幕截图 2024-01-31 234319.png" style="zoom:80%;" />

通过上面的介绍可以看出，任何大于10字节的分配请求都会失败（返回NULL），因为 没有足够的连续可用空间。而恰好10字节的需求可以由两个空闲块中的任何一个满足。但 是，如果申请小于10字节空间，会发生什么？ 

假设我们只申请一个字节的内存。在这种情况下，分配系统会执行所谓的分割（splitting）动作：它找到一块可以满足请求的空闲空间，将其分割，第一块返回给用户，第二块留在空闲列表里。

在我们的例子中，假设这时遇到申请一个字节的请求，分配程序选择使用第二块 空闲空间，对malloc()的调用会返回20（1字节分配区域的地址），空闲列表会变成这样： 

<img src="D:\OS-TEP\OS-TEP\note\第17章 空闲空间管理\屏幕截图 2024-01-31 234549.png" style="zoom:80%;" />

从上面可以看出，空闲列表基本没有变化，只是第二个空闲区域的起始位置由20变成 21，长度由 10 变为 9 了。一次你，如果请求的空间大小小于某块空闲块，分配程序通常会进行分割。

许多分配程序中因此也有一种机制，名为合并（coalescing）。还是看前面的例子（10 字节的空闲空间，10字节的已分配空间，和另外10字节的空闲空间）

对于这个（小）堆，如果应用程序调用free(10)，归还堆中间的空间，会发生什么？如 果只是简单地将这块空闲空间加入空闲列表，不多想想，可能得到如下的结果：

<img src="D:\OS-TEP\OS-TEP\note\第17章 空闲空间管理\屏幕截图 2024-01-31 234714.png" style="zoom:80%;" />

问题出现了：尽管整个堆现在完全空闲，但它似乎被分割成了3个10字节的区域。这时， 如果用户请求20字节的空间，简单遍历空闲列表会找不到这样的空闲块，因此返回失败。

为了避免这个问题，分配程序会在释放一块内存时合并可用空间。想法很简单：在归还一块空闲内存时，仔细查看要归还的内存块的地址以及邻近的空闲空间块。如果新归还的空格键与原有空闲块相邻，就将它们合并为一个较大的空闲块。

<img src="D:\OS-TEP\OS-TEP\note\第17章 空闲空间管理\屏幕截图 2024-01-31 235002.png" style="zoom:80%;" />

实际上，这是堆的空闲列表最初的样子，在所有分配之前。通过合并，分配程序可以 更好地确保大块的空闲空间能提供给应用程序。

###### 追踪已分配空间的大小 

你可能注意到，free(void *ptr)接口没有块参数的大小。因此它是假定，对于给定的指针，内存分配库可以很快确定要释放空间的大小，从而将它放回空闲列表。

要完成这个任务，大多数分配程序都会在头块(header)中保存一点额外的信息，它在内存中，通常就在返回的内存块之前。

我们再看一个例子。在这个例子中，我们检查一个20 字节的已分配块，由ptr 指着，设想用户调用了 malloc()，并将结果保存在 ptr 中：ptr = malloc(20)。

该头块中至少包含所分配空间的大小。它也可能包含一些**额外的指针来加速空间释放**，包含一个幻数来提供完整性检查，以及其他信息。我们假定，一个简单的头块包含了分配空间的大小和一个**幻数**：

```c
typedef struct  
    int size; 
    int magic; 
} header_t; 
```

上面的例子看起来会像图17.2的样子。用户调用free(ptr)时，库会通过简单的指针运算 得到头块的位置：

```c
void free(void *ptr) { 
    header_t *hptr = (void *)ptr - sizeof(header_t); //因为地址向下增长，我们还有连同头块一起释放，所以是ptr - sizeof(头块)
}
```

<img src="D:\OS-TEP\OS-TEP\note\第17章 空闲空间管理\屏幕截图 2024-02-01 000502.png" style="zoom:80%;" />

获得头块的指针后，库可以很容易地确定幻数是否符合预期的值，作为正确性检查(assert（hptr->magic == 1234567）)，并简要计算要释放的空间的大小（头块的大小 + 区域的长度）。请注意前一句话中一个小但重要的细节：实际上释放的是头块大小加上分配给用户的空间的大小。因此，如果用户请求N字节的内存，库不是在寻找大小为N的空闲块，而是在寻找N加上头块大小的空闲块。

> "幻数"（Magic Number）是在计算机领域中用来标识数据结构或文件格式的特殊值。它通常是一个固定的数值或者字符串，被设计成在数据结构的开头或文件的特定位置出现。幻数的存在可以帮助程序快速识别数据的格式或有效性，提高数据的完整性和安全性。（就是一种包含信息的标识符）

>
> 在动态内存分配的情境中，如果头块包含一些额外的指针，这些指针可以用来加速空间的释放。具体而言，这种技术通常涉及到管理数据结构的设计，其中头块包含指向其他资源的引用或信息。以下是一些可能的方式：
>
> 1. **指向相邻空闲块的指针：** 头块可能包含指向相邻的空闲内存块的指针。这样，当需要释放一个内存块时，程序可以通过头块中的指针快速找到相邻的空闲块，并进行合并。这有助于防止内存碎片化，提高内存的利用率。
> 2. **指向分配的相关数据结构：** 如果内存分配器使用了复杂的数据结构来管理分配和释放的内存块，头块可能包含指向这些数据结构的指针。这样一来，在释放内存时，程序可以更迅速地与内存分配器的数据结构进行交互，减少搜索或遍历的时间。
> 3. **指向用户自定义的释放函数：** 头块中可能包含一个指向用户定义的释放函数的指针。这样，当释放内存时，可以通过这个指针调用用户提供的释放逻辑，从而提高灵活性和定制性。

###### 嵌入空闲列表 

到目前为止，我们这个简单的空闲列表还只是一个概念性的存在，它就是一个列表，描述了堆中的空闲内存块。但如何在空闲内存自己内部建立这样一个列表呢？（为什么不用GDT:angry:）

在更典型的列表中，如果要分配新节点，你会调用？malloc()来获取该节点所需的空间。遗憾的是，在内存分配库内，你无法这么做！你需要在空闲空间本身建立空闲空间列表（就是说我们不能调用malloc()接口）.

假设我们需要管理一个4096字节的内存块（即堆是4KB）。为了将它作为一个空闲空间列表来管理，首先我们要初始化这个了表。开始，列表中只有一个条目，记录了大小为4096的空间（减去头块的大小）。下面是该列表一个节点描述（或者说一个代表空闲空间的节点描述）:

```c
typedef struct  node_t {  
 int size; 
 struct  node_t *next;
} node_t; 
```

现在来看一些代码，它们初始化堆，并将空闲列表的第一个元素放在该空间中。。假设 堆构建在某块空闲空间上，这块空间通过系统调用 mmap()获得。这不是构建这种堆的唯一 选择，但在这个例子中很合适。下面是代码： 

```c
// mmap() returns a pointer to a chunk of free space  
node_t *head = mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_ANON|MAP_PRIVATE, -1, 0); //映射分配内存的方式
head->size    = 4096 - sizeof(node_t);  
head->next    = NULL; 
```

执行这段代码之后，列表的状态是它只有一个条目，记录大小为4088（所有空间-头节点大小8）。

是的，这是一个小堆，但对我们是一个很好的例子。head指针指向这块区域的起始地址， 假设是16KB（尽管任何虚拟地址都可以）。堆看起来如图17.3所示。

现在，假设有一个 100 字节的内存请求。为了满足这个请求，库首先要找到一个足够 大小的块。因为只有一个4088 字节的块，所以选中这个块。然后，这个块被分割（split） 为两块：一块足够满足请求（以及头块，如前所述），一块是剩余的空闲块。

假设记录头块 为8个字节（一个整数记录大小，一个整数记录幻数），堆中的空间如图17.4所示。

<img src="D:\OS-TEP\OS-TEP\note\第17章 空闲空间管理\屏幕截图 2024-02-01 004607.png" style="zoom: 67%;" />

至此，对于100 字节的请求，库从原有的一个空闲块中分配了108字节，返回指向它 的一个指针（在上图中用ptr表示），并在其之前连续的8字节中记录头块信息，供未来的 free()函数使用。同时将列表中的空闲节点缩小为3980字节（4088−108）。 

现在再来看该堆，其中有3个已分配区域，每个100（加上头块是108）。这个堆如图17.5 所示。 

可以看出，堆的前324字节已经分配，因此我们看到该空间中有3个头块，以及3个100 字节的用户使用空间。空闲列表还是无趣：只有一个节点（由head指向），但在 3次分割后， 现在大小只有3764字节。但如果用户程序通过free()归还一些内存，会发生什么？

在这个例子中，应用程序调用free(16500)（根据free()的语义，填入的地址是指向分配字节的，而不是头块），归还了中间的一块已分配空间（内存块的起始地址16384 加上前一块的108，和这一块的头块的8字节，就得到了16500）。这个值在 前图中用sptr指向。 

库马上弄清楚了这块要释放空间的大小，并将空闲块加回空闲列表。假设我们将它插 入到空闲列表的头位置，该空间如图17.6所示。

<img src="D:\OS-TEP\OS-TEP\note\第17章 空闲空间管理\屏幕截图 2024-02-01 004808.png" style="zoom:67%;" />

现在的空闲列表包含一个小空闲块和一个大空闲块。

我们的列表不只有一个元素了！使得，我们的空闲空间被分割成了两段。

最后一个例子：现在假设剩余的两块已分配的空间也被释放。没有合并，空闲列表将 非常破碎，如图17.7所示。

从图中可以看出，我们现在一团糟！为什么？简单，我们忘了合并（coalesce）列表项， 虽然整个内存空间是空闲的，但却被分成了小段，因此形成了碎片化的内存空间。解决方 案很简单：遍历列表，合并（merge）相邻块。完成之后，堆又成了一个整体。

<img src="D:\OS-TEP\OS-TEP\note\第17章 空闲空间管理\屏幕截图 2024-02-01 004943.png" style="zoom:67%;" />

###### 让堆增长

我们应该讨论最后一个很多内存分配库都有的机制。具体来说，如果堆中的内存空间耗尽，应该怎么办？最简单的方式就是返回失败。在某些情况下这也是唯一的选择，因 此返回NULL也是一种体面的方式。

大多数传统的分配程序会从很小的堆开始，当空间耗尽时，再向操作系统申请更大的空 间。通常，这意味着它们进行了某种系统调用（例如，大多数UNIX系统中的sbrk），让堆增长。操作系统在执行sbrk系统调用时，会找到空闲的物理内存页，将它们映射到请求进程的 地址空间中去，并返回新的堆的末尾地址。这时，就有了更大的堆，请求就可以成功满足。 

PS:这个head居然随着每次分配空间在向下移动ww。其实根据之前看的链表图来说，也是符合常理的。

##### 17.3   基本策略

既然有了这些底层机制，让我们看看管理空闲空间的一些基本策略。这些方法大多基于简单的策略。

理想的分配程序可以同时保证快速和碎片最小化。遗憾的是，由于分配及释放的请求序列是任意的（毕竟，它们由用户程序决定）,任何特定测策略在某组不匹配的输入下都会变得非常差（在OI上就是一定能造一个样例把程序卡掉）。所以我们不会描述“最好”的策略，而是介绍一些基本的选择，并讨论它们的优缺点。

###### 最优匹配

最优匹配（best fit）策略非常简单：首先遍历整个空闲列表，找到和请求大小一样或更大的空闲块，然后返回这组候选者中最小的一块。这就是所谓的最优匹配（也可以称为最小匹配）。只需要遍历一次空闲列表，就足以找到正确的块并返回。

最优匹配背后的想法很简单：选择最接近用户请求大小的块，从而尽量避免空间浪费。然而，这有代价。简单的实现在遍历查找正确的空闲块时，要付出较高的性能代价。

###### 最差匹配

最差匹配(worst fit)方法和最优匹配相反，它尝试寻找最大的空闲块，分割并满足用户的需求后，将剩余的块(很大)加入空闲列表。最差匹配尝试在空闲列表中保留较大的块，而不是像最优匹配那样可能剩下很多难以利用的小块。但是，最差匹配同样需要遍历整个空闲列表。更糟糕的是，大多数研究表明它的表现非常差，导致过量的碎片，同时还有很高的开销。 (最差匹配虽然制造的碎片多，但它匹配的时间长啊)。

###### 首次匹配

首次匹配(first fit)策略就是找到第一个足够大的块，将请求的空间返回给用户。同样，剩余的后续空间留给后续请求。

首次匹配由速度优势(不需要遍历所有空闲块)，但有时会让空闲列表开头的部分有很多小块。（比如说一个很大的块一直在列表的前面，导致一直匹配的是这个较大的块）。因此，分配程序如何让管理空闲列表的顺序就变得很重要。一种方式是基于地址排序(address-based ordering)。通过报纸空闲块按内存地址有序，合并操作会变得很容易，从而减少了内存碎片。

###### 下次匹配

不同于首次匹配每次都从列表的开始查找，下次匹配（next fit）算法多维护一个指针， 指向上一次查找结束的位置。其想法是将对空闲空间的查找操作扩散到整个列表中去，避 免对列表开头频繁的分割。这种策略的性能与首次匹配很接它，同样避免了遍历查找。（一种对首次匹配的优化）

##### 17.4   其他方式

除了上述基本策略外，人们还提出了许多技术和算法，来改进内存分配。

###### 分离空闲列表

分离空闲列表(segregated list)的基本想法很简单：如果某个应用程序经常申请一种（或几种）大小的内存空间，那就用一个独立的列表，只管理这样大小的对象。其他大小的请求都交给更通用的内存分配程序。

这种方法的好处显而易见：通过拿出一部分内存专门满足某种大小的请求，碎片就不再是问题了。而且，由于没有复杂的列表查找过程，这种特定大小的内存分配和释放都很快。

就像所有好主意一样，这种方式也为系统引入了新的复杂性。例如，应该拿出多少内存来专门为某种大小的请求服务，而将剩余的用来满足一般请求？超级工程师Jeff Bonwick 为Solaris 系统内核设计的厚块分配程序（slab allocator），很优雅地处理了这个问题。

具体来说，在内核启动时，它为可能频繁请求的内核对象创造了一些对象缓存(object cache)，如锁和文件系统inode（索引节点）等。这些的对象的缓存中每个**分离了特定大小的空间列表**，因此能很快地相应内存请求和释放。如果某个缓存中的空闲空间快耗尽时，它就向通用内存 分配程序申请一些内存厚块（slab）（总量是页大小和对象大小的公倍数）。相反，如果给定 厚块中对象的引用计数变为 0，通用的内存分配程序可以从专门的分配程序中回收这些空 间，这通常发生在虚拟内存系统需要更多的空间的时候。

PS：就好像在空闲列表中又单独建立了一个特定的空闲列表，如果这个特定的空闲列表空间不足，就像整体的空闲列表请求厚块(slab)，如果这个特定的空闲列表不在需要了，就将其释放，把空间回收给整体的空闲列表。

> **补充：了不起的工程师真的了不起**  
>
> 像Jeff Bonwick 这样的工程师（Jeff Bonwick 不仅写了上面提到的厚块分配程序，还是令人惊叹的文件系统ZFS的负责人），是硅谷的灵魂。在每一个伟大的产品或技术后面都有这样一个人（或一小群 人），他们的天赋、能力和奉献精神远超众人。Facebook的Mark Zuckerberg曾经说过：“那些在自己的领域中超凡脱俗的人，比那些相当优秀的人强得不是一点点。”这就是为什么，会有人成立自己的公司， 然后永远地改变了这个世界（想想Google、Apple 和 Facebook）。努力工作，你也可能成为这种“以一 当百”的人。做不到的话，就和这样的人一起工作，你会明白什么是“听君一席话，胜读十年书”。如 果都做不到，那就太难过了。 

厚块分配程序比大多数分离空闲列表这得更多，它将列表中的空闲对象保持在预初始 化的状态。Bonwick 指出，数据结构的初始化和销毁的开销很大。通过将空闲对象保 持在初始化状态，厚块分配程序避免了频繁的初始化和销毁，从而显著降低了开销。 

###### 伙伴系统 

因为合并对分配程序很关键，所以人们设计了一些方法，让合并变得简单，一个好例子就是二分伙伴分配程序（binary buddy allocator）。（我敢说二分绝对是我见过翻译的最差的名词之一了，叫二元或者二进制多好）

在这种系统中，空闲空间首先从概念上被看成大小为2N的大空间。当有一个内存分配请求时，空闲空间被递归地一分为二，直到刚好可以满足请求的大小（再一分为二就无法满足）。

这时，请求的块被返回给用户。在下面的例子中，一个64KB大小的空闲空间被切分，以便提供7KB的块：

<img src="D:\OS-TEP\OS-TEP\note\第17章 空闲空间管理\屏幕截图 2024-02-01 174319.png" style="zoom: 80%;" />

在这个例子中，最左边的8KB块被分配给用户（如上图中深灰色部分所示）。请注意， 这种分配策略只允许分配2的整数次幂大小的空闲块，因此会有内部碎片（internal fragment） 的麻烦。

伙伴系统的漂亮之处在于块被释放时。如果将这个8KB的块归还给空闲列表，分配程 序会检查“伙伴”8KB 是否空闲。如果是，就合二为一，变成 16KB 的块。然后会检查这 个16KB块的伙伴是否空闲，如果是，就合并这两块。这个递归合并过程继续上溯，直到合 并整个内存区域，或者某一个块的伙伴还没有被释放。（线段树？）

伙伴系统运转良好的原因，在于很容易确定某个块的伙伴。怎么找？仔细想想上面例 子中的各个块的地址。如果你想得够仔细，就会发现**每对互为伙伴的块只有一位不同**，**正是这一位决定了它们在整个伙伴树中的层次**。（不应该是两位吗，因为肯定是二进制进一位啊）

###### 其他想法

上面提到的众多方法都有一个重要的问题，缺乏可扩展性（scaling）。具体来说，就是 查找列表可能很慢。因此，更先进的分配程序采用更复杂的数据结构来优化这个开销，牺牲简单性来换取性能。例子包括平衡二叉树、伸展树和偏序树。 

考虑到现代操作系统通常会有多核，同时会运行多线程的程序，因此人们这了许多工作，提升分配程序在多核系统上的表现。

##### 17.5   小结

在本章中，我们讨论了最基本的内存分配程序形式。这样的分配程序存在于所有地方， 与你编写的每个 C 程序链接（链接阶段就包含了），也和管理其自身数据结构的内存的底层操作系统链接。对分配程序提供的确切工作负载了解得越多，就越能调整它以更好地处理这种工作负载。