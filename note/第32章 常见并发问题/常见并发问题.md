#### 常见并发问题

多年来，研究人员花了大量的时间和精力研究并发编程的缺陷。在本章中，我们会简要了解一些并发编程的例子，以便更好地理解要注意什么问题。

> **关键问题：如何处理常见的并发缺陷** 
>
> 并发缺陷会有很多常见的模式。了解这些模式是写出健壮、正确程序的第一步。

##### 32.1 有哪些类型的缺陷 

Lu等人详细分析了一些流行的并发应用，以理解实践中有哪些类型的缺陷。

![](D:\OS-TEP\OS-TEP\note\第32章 常见并发问题\屏幕截图 2024-01-29 174426.png)

其中大多数是非死锁相关的（74个），剩余31个是死锁缺陷。

对于第一类非死锁的缺陷，我们通过该研究的例子来讨论。

对于第二类死锁缺陷，我们讨论人们在阻止、避免和处理死锁上完成的大量工作。

##### 32.2 非死锁缺陷

非死锁问题占了并发问题的大多数，他们是怎么发生的？我们如何修复？

我们现在主要讨论两种：违反原子性（atomicity violation）和错误顺序(order violation)。

###### 违反原子性缺陷 

第一种类型的问题叫做违反原子性，这是一个MySQL中出现的例子。

```c
//Thread 1::
if (thd->proc_info) {
	...
	fputs(thd->proc_info, ...);
	...
}

//Thread 2::
thd->proc_info = NULL;
```

错误显而易见，在完成Thread1的if语句后，中断产生进入Thread2，之后再返回Thread1，会导致错误。

根据Lu等人，更正式的违反原子性的定义是：“违反了多次内存访问中预期的可串行性（即代码段本意是原子的，但在执行过程中并没有强制执行原子性）”。

在我们的例子中， proc_info 的非空检查和 fputs()调用打印 proc_info 是假设原子的，当假设不成立时，代码就出问题了。

这种问题的修复通常（但不总是）很简单。

在这个方案中，我们只要给共享变量的访问加锁，确保每个线程访问 proc_info 字段时， 都持有锁（proc_info_lock）。当然，访问这个结构的所有其他代码，也应该先获取锁。

```c
pthread_mutex_t proc_info_lock = PTHREAD_MUTEX_INITIALIZER;

//Thread 1::
pthread_mutex_lock(&proc_info_lock);
if (thd->proc_info) {
	...
	fputs(thd->proc_info, ...);
	...
}
pthread_mutex_unlock(&proc_info_lock);


//Thread 2::
pthread_mutex_lock(&proc_info_lock);
thd->proc_info = NULL;
pthread_mutex_unlock(&proc_info_lock);
```

###### 违反顺序缺陷

Lu等人提出的另一种常见的非死锁问题叫做违反顺序（order violation）。下面是一个简单的例子。

```c
//Thread 1::
void init() {
	...
	mThread = PR_CreateThread(mMain, ...);
	...
}

//Thread 2::
void mMain(...) {
	...
	mState = mThread->State;
	...
}

```

线程2的代码似乎假定mThread已经被初始化了。然而只要线程2先执行，就可能会引发空指针崩溃，甚至产生更奇怪的问题（因为线程2会读到任意的内存位置）。

违反顺序的更正式的定义是：“两个内存访问的预期顺序被打破了（即A应该在B之前执行，但是实际运行中却不是这个顺序）”

我们通过强制顺序来修复这种缺陷。正如之前所讨论的，条件变量（condition variables）就是一种简单可靠的方式，在现代代码集中加入这种同步。

```c
pthread_mutex_t mtLock = PTHREAD_MUTEX_INITIALIZER;
pthread_cond_t mtCond = PTHREAD_COND_INITIALIZER;
int mtInit = 0;

Thread 1::
void init() {
	...
	mThread = PR_CreateThread(mMain, ...);

	// signal that the thread has been created...
	pthread_mutex_lock(&mtLock);
	mtInit = 1; //代表线程被初始化的全局变量
	pthread_cond_signal(&mtCond);
	pthread_mutex_unlock(&mtLock);
	...
}

Thread 2::
void mMain(...) {
	...
	// wait for the thread to be initialized...
	pthread_mutex_lock(&mtLock);
	while (mtInit == 0)
		pthread_cond_wait(&mtCond, &mtLock);
	pthread_mutex_unlock(&mtLock);

	mState = mThread->State;
	...
}
```

在这段修复的代码中，我们增加了一个锁（mtLock）、一个条件变量（mtCond）以及状 态的变量（mtInit）。初始化代码运行时，会将 mtInit 设置为 1，并发出信号表明它已做了这 件事。

请注意，我们可以用 mThread 本 身作为状态变量，但为了简洁，我们没有这样做。当线程之间的顺序很重要时，条件变量 （或信号量）能够解决问题。

###### 非死锁缺陷：小结

Lu 等人的研究中，大部分（97%）的非死锁问题是违反原子性和违反顺序这两种。

因此，程序员仔细研究这些错误模式，应该能够更好地避免它们。

然而，并不是所有的缺陷都像我们举的例子一样，这么容易修复。有些问题需要对应 用程序的更深的了解，以及大量代码及数据结构的调整。

##### 32.3 死锁缺陷

死锁（deadlock）是一种在许多复杂并发系统中出现的经典问题。

例如，当线程 1 持有锁 L1，正在等待另外一个锁 L2，而线程 2 持有锁 L2，却在等 待锁 L1 释放时，死锁就产生了。

```c
Thread 1: Thread 2: 
lock(L1); lock(L2); 
lock(L2); lock(L1); 
```

这段代码运行时，不是一定会出现死锁的。当线程 1 占有锁 L1，上下文切换到线程 2。 线程 2 锁住 L2，试图锁住 L1。这时才产生了死锁，两个线程互相等待。如图 32.1 所示，其 中的圈（cycle）表明了死锁。

<img src="D:\OS-TEP\OS-TEP\note\第32章 常见并发问题\屏幕截图 2024-01-29 181733.png" style="zoom: 67%;" />

> **关键问题：如何对付死锁** 
>
> 我们在实现系统时，如何避免或者能够检测、恢复死锁呢？这是目前系统中的真实问题吗？

###### 为什么发生死锁 

你可能在想，上文提到的这个死锁的例子，很容易就可以避免。例如，只要线程 1 和 线程 2 都用相同的抢锁顺序，死锁就不会发生。那么，死锁为什么还会发生？

其中一个原因是，在大型的代码库里，组件之间会有复杂的依赖。因此，在设计大型系统的锁机制时，必须要仔细地去避免循环依赖导致的死锁。

另一个原因是封装（encapsulation）。软件开发者一直倾向于因此实现细节，以模块化地方式让软件开发更容易。然而，模块化和锁不是很契合，某些看起来没有关系的接口可能会导致死锁。

```java
//This is java code.
Vector v1, v2; 
v1.AddAll(v2); 
```

在内部，这个方法需要多线程安全，因此针对被添加向量（v1）和参数（v2）的锁都 需要获取。假设这个方法，先给 v1 加锁，然后再给 v2 加锁。如果另外某个线程几乎同时 在调用 v2.AddAll(v1)，就可能遇到死锁。

###### 产生死锁的条件

死锁的产生需要如下4个条件。

- 互斥：线程对于需要的资源需要互斥的访问。（例如一个线程抢到锁）。
- 持有并等待：线程持有了资源（例如已经持有的锁），同时又在等待其他资源（例如，需要获得的锁）。
- 非抢占：线程获得的资源（例如锁），不能被抢占。
- 循环等待：线程之间存在一个**环路**，环路上每个线程都额外持有一个资源，而这个资源优势下一个线程要申请的。（解决哲学家就餐问题的方式）

这4个条件只要有一个没有被满足，死锁就不会产生。

因此，我们首先研究一下预防死锁的方法：每个策略都设法阻止某一个条件，从而解决死锁的问题。

###### 预防

**循环等待**

也许最实用的预防计数（当然也是经常采用的），就是让代码不会产生循环等待。最直接的方法就是获取锁时提供一个全序（total ordering）。假如系统共有两个锁（L1和L2），那么我们每次都先申请L1然后再申请L2，就可以避免死锁。这样严格的顺序避免了循环等待，也就不会产生死锁。

当然，更复杂的系统中不止会有两个锁，所得全序可能很难做到。因此，偏序（partial ordering）可能时一种有用的方法，安排锁的获取并避免死锁。

Linux中的内存映射代码就是一个偏序锁的好例子，其表明了10种不同的加锁顺序，比如比如 i_mutex 早于 i_mmap_mutex，也包括复杂的关系，比如 i_mmap_mutex 早于 private_lock，早于 swap_lock，早于 mapping->tree_lock。

你可以想到，全序和偏序都需要细致的锁策略的设计和实现。另外，顺序只是一种约 定，粗心的程序员很容易忽略，导致死锁。最后，有序加锁需要深入理解代码库，了解各 种函数的调用关系，即使一个错误，也会导致死锁。

> **提示：通过锁的地址来强制锁的顺序** 
>
> 当一个函数要抢多个锁时，我们需要注意死锁。比如有一个函数：do_something(mutex t *m1, mutex  t *m2)，如果函数总是先抢 m1，然后 m2，那么当一个线程调用 do_something(L1, L2)，而另一个线程调 用 do_something(L2, L1)时，就可能会产生死锁。  
>
> 为了避免这种特殊问题，聪明的程序员根据锁的地址作为获取锁的顺序。按照地址从高到低，或者 从低到高的顺序加锁，do_something()函数就可以保证不论传入参数是什么顺序，函数都会用固定的顺序加锁。具体的代码如下： 
>
> ```c
> if (m1 > m2) { // grab locks in high-to-low address order  
>     pthread_mutex_lock(m1);  
>     pthread_mutex_lock(m2);  
> } else {
>     pthread_mutex_lock(m2);  
>     pthread_mutex_lock(m1);
> }  
> // Code assumes that m1 != m2 (it is not the same lock)  
> ```
>
> 在获取多个锁时，通过简单的技巧，就可以确保简单有效的无死锁实现。

**持有并等待**

死锁的持有并等待条件，可以通过原子性的抢锁来避免。

```c
lock(prevention); 
lock(L1); 
lock(L2); 
... 
unlock(prevention); 
```

先抢到prevention这个锁之后，代码保证了抢锁的过程中，不会有不合时宜的线程切换，从而避免了死锁。

所以就是任何线程进行抢锁时，要先抢到全局的prevention锁。（就是确保一次把该抢的锁全部抢到）

注意：出于某些原因，这个方案也有问题。和之前一样，它不适用于封装：因为这个方案需要我们准确地知道要抢哪些锁，并且提前抢到这些锁。

因为要提前抢到所有锁，而不是在真正需要的时候，所以可能降低了并发。

**非抢占**

在调用 unlock 之前，都认为锁是被占有的，多个抢锁操作通常会带来麻烦，因为我们等待一个锁时，同时持有另一个锁。

很多线程库提供更为灵活的接口来避免这种情况。具 体来说，trylock()函数会尝试获得锁，或者返回−1，表示锁已经被占有。你可以稍后重试一下。

可以用这一接口来实现无死锁的加锁方法：

```c                  
top:
lock(L1);
if (trylock(L2) == -1) {
	unlock(L1);
	goto top;
}
```

就是说，如果第二把锁获取不到，就把第一把锁也给释放掉。

注意，另一个线程可以使用相同的加锁方式，但是不同的加锁顺序（L2 然后 L1），程序仍然不会产生死锁。

但是会引来一个新的问题：活锁（livelock）。两个线程有可能一直 重复这一序列，又同时都抢锁失败。

这种情况下，系统一直在运行这段代码（因此不是死 锁），但是又不会有进展，因此名为活锁。

也有活锁的解决方法：例如，可以在循环结束 的时候，先随机等待一个时间，然后再重复整个动作，这样可以降低线程之间的重复互相干扰。

关于这个方案的最后一点：使用 trylock 方法可能会有一些困难。第一个问题仍然是封装：如果其中的某一个锁，是封装在函数内部的，那么这个跳回开始处就很难实现。如果代码在中途获取了某些资源，必须要确保也能释放这些资源。

例如，在抢到 L1 后，我们的代码分配了一些内存，当抢 L2 失败时，并且在返回开头之前，需要释放这些内存。当然， 在某些场景下（例如，之前提到的 Java 的 vector 方法），这种方法很有效。

就是说放回L1的实际意义就是撤回此线程中，你所做过的所有操作。

**互斥** 

最后的预防方法是完全避免互斥。通常来说，代码都会存在临界区，因此很难避免互 斥。那么我们应该怎么做呢？

Herlihy 提出了设计各种无等待（wait-free）数据结构的思想[H91]。想法很简单：通过 强大的硬件指令，我们可以构造出不需要锁的数据结构。

举个简单的例子，假设我们有比较并交换（compare-and-swap）指令，是一种由硬件提 供的原子指令，做下面的事：

```c
int CompareAndSwap(int *address, int expected, int new) {
	if (*address == expected) {
		*address = new;
		return 1; // success
	}
	return 0; // failure
}
```

假定我们想原子地给某个值增加特定的数量。我们可以这样实现：

```c
void AtomicIncrement(int *value, int amount) {
	do {//其实这里是if语义 但是中断的产生要求我们必须检查状态
		int old = *value;	//如果value在更新时不等于old 这说明临界区的状态改变了
        					//此时我们就要再次更新old 直到old和value的值相等，我们才给数值加上特定的值
	} while (CompareAndSwap(value, old, old + amount) == 0);
}
```

无须获取锁，更新值，然后释放锁这些操作，我们使用比较并交换指令，反复尝试将值更新到新的值。这种方式没有使用锁，因此不会有死锁（有可能产生活锁）。

我们来考虑一个更复杂的例子：链表插入。这是在链表头部插入元素的代码：

```c
 void insert(int value) { 
     node_t *n = malloc(sizeof(node_t)); 
     assert(n != NULL); 
     n->value = value; 
     n->next = head; 
     head = n;
} 
```

PS: head 就是临界区的值，所以要加锁保护。

这段代码在多线程同时调用的时候，会有临界区（看看你是否能弄清楚原因）。当然， 我们可以通过给相关代码加锁，来解决这个问题：

```c
void insert(int value) { 
    node_t *n = malloc(sizeof(node_t)); 
    assert(n != NULL); 
    n->value = value; 
    lock(listlock); // begin critical section 
    n->next = head; 
    head = n; 
    unlock(listlock); // end of critical section 
}
```

>  聪明的读者可能会问，为什么我们这么晚才抢锁，而不是就在进入 insert()时。聪明的读者，你可以弄清楚为什么这可能是正确的？

因为我们只有在分配内存成功之后才进行插入操作，如果提前上锁而获取内存失败，可能导致锁无法被还回去。

这里我们尝试用比较并交换指令（compare-and-swap) 来实现插入操作。一种可能的实现是：

```c
void insert(int value) {
	node_t *n = malloc(sizeof(node_t));
	assert(n != NULL);
	n->value = value;
	do {
		n->next = head;//和上面同理 只有在两个操作之间head未发生变化 才进行插入操作
	} while (CompareAndSwap(&head, n->next, n) == 0);
}
```

这段代码，首先把 next 指针指向当前的链表头（head），然后试着把新节点交换到链表 头。但是，如果此时其他的线程成功地修改了 head 的值，这里的交换就会失败，导致这个线程根据新的 head 值重试。

**通过调度避免死锁** 

除了死锁预防，某些场景更适合死锁避免（avoidance）。我们需要了解全局的信息，包括不同线程在运行中对锁的需求情况，从而使得后续的调度能够避免产生死锁。

例如，假设我们需要在两个处理器上调度 4 个线程。更进一步，假设我们知道线程 1 （T1）需要用锁 L1 和 L2，T2 也需要抢 L1 和 L2，T3 只需要 L2，T4 不需要锁。我们用表 32.2 来表示线程对锁的需求。

![](D:\OS-TEP\OS-TEP\note\第32章 常见并发问题\屏幕截图 2024-01-29 233641.png)

一种比较聪明的调度方式是，只要 T1 和 T2 不同时运行，就不会产生死锁。下面就是 这种方式：

<img src="D:\OS-TEP\OS-TEP\note\第32章 常见并发问题\屏幕截图 2024-01-29 233657.png" style="zoom:67%;" />

请注意，T3 和 T1 重叠，或者和 T2 重叠都是可以的。虽然 T3 会抢占锁 L2，但是由于 它只用到一把锁，和其他线程并发执行都不会产生死锁。

我们再来看另一个竞争更多的例子。在这个例子中，对同样的资源（又是锁 L1 和 L2） 有更多的竞争。锁和线程的竞争如表 32.3 所示。

![](D:\OS-TEP\OS-TEP\note\第32章 常见并发问题\屏幕截图 2024-01-29 233709.png)

特别是，线程 T1、T2 和 T3 执行过程中，都需要持有锁 L1 和 L2。下面是一种不会产 生死锁的可行方案：

<img src="D:\OS-TEP\OS-TEP\note\第32章 常见并发问题\屏幕截图 2024-01-29 233721.png" style="zoom:67%;" />

你可以看到，T1、T2 和 T3 运行在同一个处理器上，这种保守的静态方案会明显增加 完成任务的总时间。尽管有可能并发运行这些任务，但为了避免死锁，我们没有这样做， 付出了性能的代价。

Dijkstra 提出的银行家算法[D64]是一种类似的著名解决方案，文献中也描述了其他类似 的方案。遗憾的是，这些方案的适用场景很局限。例如，在嵌入式系统中，你知道所有任 务以及它们需要的锁。

另外，和上文的第二个例子一样，这种方法会限制并发。因此，通过调度来避免死锁不是广泛使用的通用方案。

**检查和恢复**

最后一种常用的策略就是允许死锁偶尔发生，检查到死锁时再采取行动。举个例子， 如果一个操作系统一年死机一次，你会重启系统，然后愉快地（或者生气地）继续工作。 如果死锁很少见，这种不是办法的办法也是很实用的。

> 提示：不要总是完美（TOM WEST 定律） 
>
> Tom West 是经典的计算机行业小说《Soul of a New Machine》[K81]的主人公，有一句很棒的工程格言： “不是所有值得做的事情都值得做好”。如果坏事很少发生，并且造成的影响很小，那么我们不应该去花费大 量的精力去预防它。当然，如果你在制造航天飞机，事故会导致航天飞机爆炸，那么你应该忽略这个建议。

很多数据库系统使用了死锁检测和恢复技术。死锁检测器会定期运行，通过构建资源 图来检查循环。当循环（死锁）发生时，系统需要重启。如果还需要更复杂的数据结构相 关的修复，那么需要人工参与。

##### 32.4 小结 

在本章中，我们学习了并发编程中出现的缺陷的类型。第一种是非常常见的，非死锁缺陷，通常也很容易修复。这种问题包括：违法原子性，即应该一起执行的指令序列没有 一起执行；违反顺序，即两个线程所需的顺序没有强制保证。

同时，我们简要地讨论了死锁：为何会发生，以及如何处理。这个问题几乎和并发一 样古老，已经有成百上千的相关论文了。实践中是自行设计抢锁的顺序，从而避免死锁发生。无等待的方案也很有希望，在一些通用库和系统中，包括 Linux，都已经有了一些无等 待的实现。

然而，这种方案不够通用，并且设计一个新的无等待的数据结构极其复杂，以 至于不够实用。也许，最好的解决方案是开发一种新的并发编程模型：在类似 MapReduce （来自 Google）[GD02]这样的系统中，程序员可以完成一些类型的并行计算，无须任何锁。 锁必然带来各种困难，也许我们应该尽可能地避免使用锁，除非确信必须使用

------

分享一首小诗：

有国才有家，

有孩才有妈。

没有谭浩强，

哪有C + + 。